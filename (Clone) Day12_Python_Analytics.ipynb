{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42ec965d-f570-469d-9fa1-dfe436f81827",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_df = spark.read.csv(\"/FileStore/Day6Data_dbfs.csv\", header=\"True\")\n",
    "display(csv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fad91a83-8281-45dc-b43f-6925220723aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import explode\n",
    "from pyspark.sql import *\n",
    "import pandas as pd\n",
    "\n",
    "display(sql(\"select * from day10.temperature\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "662ec00a-e718-4a51-bbdc-9fd10eeb2b18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#for display\n",
    "display(sql(\"select * from day10.temperature\"))\n",
    "\n",
    "#to save to variable\n",
    "df = sql(\"select * from day10.temperature\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0251fd04-90af-43bf-abc4-4f7b333e1fe9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#will return errors\n",
    "dfa = pd.DataFrame(data=df)\n",
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a943c586-6772-4ec7-a792-bd3a3393c43d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#so we need to use toPandas():\n",
    "dfa2 = df.toPandas()\n",
    "dfa2.astype({'mean_daily_temp': 'float'}).dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "117f424f-a012-4809-9c21-26ad28493ccb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dfa2.plot.scatter(x='date',y='mean_daily_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8458dd2b-ff68-424e-9d32-a04d2652e1da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = sql(\"select * from day10.temp2\")\n",
    "dfa1 = df1.toPandas()\n",
    "dfa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e4cb7b8-3fa3-48f5-a6c5-197f5dfb3db4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_concat = pd.concat([dfa1,dfa2], keys=['name', 'city'])\n",
    "result_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef53617c-922c-4377-b3d7-a75863b8c730",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_merge = pd.merge(dfa1, dfa2, how='left', left_on='name', right_on='city')\n",
    "result_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e23a96a6-da60-49d5-9a46-c247e3d7dd4b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's get now some data from Databricks sample data (that is available to anybody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4842583d-7b7e-4c21-ad50-67a168161cb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfcovid = pd.read_csv(\"/dbfs/databricks-datasets/COVID/covid-19-data/us-states.csv\")\n",
    "dfcovid.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72423a41-bdb5-42ce-9d5d-9d4337aafd29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "and now let's scatter plot some number of cases and deaths per states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f9b3a19-f613-4f64-bc12-40776a7b609e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter to 2020-12-01 on first of december\n",
    "df_12_01 = dfcovid[dfcovid[\"date\"] == \"2020-12-01\"] \n",
    "\n",
    "ax = df_12_01.plot(x=\"cases\", y=\"deaths\", kind=\"scatter\", \n",
    "                   figsize=(12,8), s=100, title=\"Deaths vs Cases on 2020-12-01 - All States\")\n",
    "\n",
    "df_12_01[[\"cases\", \"deaths\", \"state\"]].apply(lambda row: ax.text(*row), axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ceca2917-0f40-4737-8504-ea6a366b2077",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "And now let's compare only couple of these extreme states (New York, Texas, California and Florida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb7a28df-cc08-4840-9f7a-c4e40d6546b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_ny_cal_tex_flor = dfcovid[(dfcovid[\"state\"] == \"New York\") | (dfcovid[\"state\"] == \"California\") | (dfcovid[\"state\"] == \"Florida\") | (dfcovid[\"state\"] == \"Texas\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beee87dd-e1fb-4dda-8a5f-7176617c96a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's pivot our df_ny_cali DataFrame so that we can plot deaths over time for all states\n",
    "df_ny_cal_tex_flor = df_ny_cal_tex_flor.pivot(index='date', columns='state', values='deaths').fillna(0)\n",
    "df_ny_cal_tex_flor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "979741d7-aad6-45df-b6df-5a3ba7e45f6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "and now plot this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "799a4aaf-cfc2-4c9d-97bf-602eb97cab7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_ny_cal_tex_flor.plot.line(title=\"Deaths 2020-01-25 to 2020-12-10 - CA, NY, TX, FL\", figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d24ba233-dd1e-4a47-bf7e-d7a069960f58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "And now for a simple regression analysis, we will split data from test and train. Since the first and second wave we will need to thing how to split the data.\n",
    "Let's split it until mid of November and after mid of November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cb1d94b-7c6e-4ccb-8137-8ac0d3f9d7b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df = dfcovid[(dfcovid[\"date\"] >= \"2020-07-01\") & (dfcovid[\"date\"] <= \"2020-11-15\")]\n",
    "test_df = dfcovid[dfcovid[\"date\"] > \"2020-11-16\"]\n",
    "\n",
    "X_train = train_df[[\"cases\"]]\n",
    "y_train = train_df[\"deaths\"]\n",
    "\n",
    "X_test = test_df[[\"cases\"]]\n",
    "y_test = test_df[\"deaths\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5afe9722-b606-4679-958d-3833f930c17c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We will use scikit-learn to do simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2efc679c-039d-4bc8-8b0c-d593be3bdda7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(f\"num_deaths = {lr.intercept_:.4f} + {lr.coef_[0]:.4f}*cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bed580e-438f-4a29-912f-61877e29d985",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "So if we have no cases, then there should be no deaths caused by COVID-19; this gives us a base line and assume that let's set the intercept to be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ebab12b-043b-438d-9faf-e43936d9acdd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "print(f\"num_deaths = {lr.coef_[0]:.4f}*cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "771bfe82-fd3a-4145-8872-97d3bff14795",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This model imposes that there is a 2.68% mortality rate in our dataset. But we know that some states have higher mortality rates and that linear model is absolutely not ideal for that, but it is just to showcase for using Python in Databricks."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Day12_Python_Analytics",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
